{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our Project Dataframe\n",
    "df = pd.read_csv('product_sales.csv')\n",
    "\n",
    "# Additional Mapping file U.S. Census Beurau Regions\n",
    "state_region = pd.read_csv('state_region_mapping.csv')\n",
    "\n",
    "# Merge\n",
    "df = df.merge(state_region[['State','Region']].rename(columns={'State':'state','Region':'region'}), on='state',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_null_values(data, bar_width=0.4):\n",
    "    # Calculate null values for each column\n",
    "    null_counts = data.isnull().mean() * 100\n",
    "\n",
    "    # Format the percentages\n",
    "    null_counts_formatted = null_counts.apply(lambda x: f'{x:.1f}%')\n",
    "\n",
    "    # Create a bar plot\n",
    "    fig = go.Figure(go.Bar(\n",
    "        x=null_counts.index,\n",
    "        y=null_counts.values,\n",
    "        text=null_counts_formatted.values,\n",
    "        textposition='auto',\n",
    "        marker_color='rgb(55, 83, 109)',\n",
    "        width=bar_width,\n",
    "    ))\n",
    "\n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        title='Percentage of Null Values in Each Column',\n",
    "        xaxis_title='Columns',\n",
    "        yaxis_title='Percentage of Null Values',\n",
    "        showlegend=False,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Call the function to visualize null values\n",
    "visualize_null_values(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_plot(data):\n",
    "    # Iterate over columns\n",
    "    for column in data.columns:\n",
    "        # Check data type\n",
    "        if pd.api.types.is_numeric_dtype(data[column]):\n",
    "            # If numeric, plot histogram\n",
    "            fig = px.histogram(data, x=column, title=f'Histogram for {column}', labels={'y': 'Count'})\n",
    "            fig.update_traces(texttemplate='%{y}', textposition='inside')\n",
    "            fig.show()\n",
    "        else:\n",
    "            # If categorical, plot bar chart\n",
    "            fig = px.bar(data[column].value_counts().reset_index(), x='index', y=column, \n",
    "                         title=f'Bar Chart for {column}', labels={'index': 'Categories', column: 'Count'})\n",
    "            fig.update_traces(texttemplate='%{y}', textposition='inside')\n",
    "            fig.show()\n",
    "\n",
    "\n",
    "# Call the function to auto-plot\n",
    "auto_plot(df.drop(columns=['customer_id']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation\n",
    "\n",
    "- week:\n",
    "    - Nothing to clean up\n",
    "\n",
    "- sales_method:\n",
    "    - Sames values, different punctuation or simplified text.\n",
    "    - Bring these into 3 values by:\n",
    "        - em + call -> Email + Call\n",
    "        - email -> Email\n",
    "\n",
    "- nb_sold\n",
    "    - Nothing to clean up\n",
    "\n",
    "\n",
    "- revenue:\n",
    "    - 7.2% of the records have null values.\n",
    "    - **Decision** Input the median value of this column when it is null.\n",
    "\n",
    "- years_as_customer\n",
    "    - Few outliers, max being 63 and average 4.965933.\n",
    "    - I do not have enough contextual information around this dataset/company to exclude or manipulate.\n",
    "    - **Decision** given the above, I will not be excluding this.\n",
    "\n",
    "- nb_cite_visits\n",
    "    - Nothing to clean up\n",
    "\n",
    "- state\n",
    "    - I am bringing in a seperate dataset to map region to states in order to limit this column to a limitted set of values.\n",
    "    - Focus more on regions could give us a more focused approach to analyzing location data.\n",
    "\n",
    "- region\n",
    "    - Nothing to clean up with state, noting to clean up with region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales_method cleaning\n",
    "df.loc[df['sales_method'] == 'em + call', 'sales_method'] = 'Email + Call'\n",
    "df.loc[df['sales_method'] == 'email', 'sales_method'] = 'Email'\n",
    "\n",
    "# Clean-up revenue\n",
    "df.loc[df['revenue'].isna(), 'revenue'] = df.dropna(subset=['revenue'])['revenue'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA\n",
    "\n",
    "- week:\n",
    "    - First Week saw the largest number of transactions.\n",
    "        - Dropped in week's 2 and 3, then climbed up again for week's 4 and 5.\n",
    "        - Regardless, weeks 2-5 saw very similar amounts of transactions.\n",
    "    - Lowest number of transactions in final week, week 6.\n",
    "    - Right-swewed.\n",
    "\n",
    "- sales_method:\n",
    "    - Email being the most common method, Call + Email being the least common. \n",
    "        - Email:        50% of the records\n",
    "        - Call:         33% of the records\n",
    "        - Call + Email: 12% of the records\n",
    "\n",
    "- nb_sold\n",
    "    - Normally Distrubted, with small peak near the maximum.\n",
    "\n",
    "- revenue:\n",
    "    - Multi-modal with multiple peaks (~6) could indicate we are dealing with clients in different business segments (IE Large, Medium, Small, Very-Small, ...) or different products being sold.\n",
    "\n",
    "- years_as_customer\n",
    "    - Very Right-Skewed distribution, with visible outlier mentioned above.\n",
    "\n",
    "- nb_cite_visits\n",
    "    - Normall Distrubted.\n",
    "\n",
    "- region\n",
    "    - The South region being the most transactions United States, and the Northeast region having the least transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_null_values(data, bar_width=0.4):\n",
    "    # Calculate null values for each column\n",
    "    null_counts = data.isnull().mean() * 100\n",
    "\n",
    "    # Format the percentages\n",
    "    null_counts_formatted = null_counts.apply(lambda x: f'{x:.1f}%')\n",
    "\n",
    "    # Create a bar plot\n",
    "    fig = go.Figure(go.Bar(\n",
    "        x=null_counts.index,\n",
    "        y=null_counts.values,\n",
    "        text=null_counts_formatted.values,\n",
    "        textposition='auto',\n",
    "        marker_color='rgb(55, 83, 109)',\n",
    "        width=bar_width,\n",
    "    ))\n",
    "\n",
    "    # Customize layout\n",
    "    fig.update_layout(\n",
    "        title='Percentage of Null Values in Each Column',\n",
    "        xaxis_title='Columns',\n",
    "        yaxis_title='Percentage of Null Values',\n",
    "        showlegend=False,\n",
    "        template='plotly_white'\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Call the function to visualize null values\n",
    "visualize_null_values(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_plot(data):\n",
    "    # Iterate over columns\n",
    "    for column in data.columns:\n",
    "        # Check data type\n",
    "        if pd.api.types.is_numeric_dtype(data[column]):\n",
    "            # If numeric, plot histogram\n",
    "            fig = px.histogram(data, x=column, title=f'Histogram for {column}', labels={'y': 'Count'})\n",
    "            fig.update_traces(texttemplate='%{y}', textposition='inside')\n",
    "            fig.show()\n",
    "        else:\n",
    "            # If categorical, plot bar chart\n",
    "            fig = px.bar(data[column].value_counts().reset_index(), x='index', y=column, \n",
    "                         title=f'Bar Chart for {column}', labels={'index': 'Categories', column: 'Count'})\n",
    "            fig.update_traces(texttemplate='%{y}', textposition='inside')\n",
    "            fig.show()\n",
    "\n",
    "\n",
    "# Call the function to auto-plot\n",
    "auto_plot(df.drop(columns=['customer_id']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only the continuous variables\n",
    "continuous_vars = df[['nb_site_visits', 'years_as_customer', 'revenue', 'nb_sold']]\n",
    "\n",
    "# Creating a grid of scatter plots\n",
    "fig = px.scatter_matrix(continuous_vars, dimensions=list(continuous_vars.columns), \n",
    "                        labels={col:col for col in continuous_vars.columns},\n",
    "                        color_continuous_scale='RdBu', title=\"Scatterplot Matrix with Correlation Coefficients\")\n",
    "\n",
    "# Customizing layout\n",
    "fig.update_layout(\n",
    "    title=\"Scatterplot Matrix of Continuous Variables\",\n",
    "    width=800,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "# Display the plots\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "corr_matrix = continuous_vars.corr()\n",
    "\n",
    "# Create a heatmap\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "                   z=corr_matrix.values,\n",
    "                   x=corr_matrix.index,\n",
    "                   y=corr_matrix.columns,\n",
    "                   zmin=-1,\n",
    "                   zmax=1,\n",
    "                   colorscale='RdBu',\n",
    "                   colorbar=dict(title='Correlation'),\n",
    "                   text=corr_matrix.round(2)\n",
    "                ))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Correlation Matrix Heatmap',\n",
    "    xaxis=dict(tickangle=-45),\n",
    "    yaxis=dict(tickangle=45),\n",
    ")\n",
    "# Display the heatmap\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between our continuous variables\n",
    "\n",
    "- nb_site_visits and years_as_customer\n",
    "    - from the scatter plot we can see that it resembles a normal distribution.\n",
    "        - Longer a customer could ininuate that they recieved the average number of visits.\n",
    "- Revenue and number of units sold has our highest correlation coefficient, which does make sense given the nature of sales.\n",
    "- Outside of that, the correlaiton between number of site visits and number of units sold has a weak psoitive correlation. \n",
    "- I believe the remaining variables have no correlaiton to note with eachother. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many customers were there for each approach?\n",
    "\n",
    "- Email: 7466\n",
    "- Call: 4962\n",
    "- Email + Call: 2572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_method = df[df['sales_method'] == 'Email']['customer_id'].nunique()\n",
    "call_method = df[df['sales_method'] == 'Call']['customer_id'].nunique()\n",
    "call_email_method = df[df['sales_method'] == 'Email + Call']['customer_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_email_method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does the spread of the revenue look like overall? And for each method?\n",
    "\n",
    "- Overall:\n",
    "    - Multi-modal descibed in EDA.\n",
    "    - Center at (descibed by the median) 89.5.\n",
    "    - Maximum at 238.32\n",
    "    - Minimum at 32.54\n",
    "\n",
    "- Email: \n",
    "    - Highest number of transactions\n",
    "    - Fairly normally distributed, with center (decribed by median) 94.275.\n",
    "    - Maximum at 148.97\n",
    "    - Minumum at 78.83\n",
    "\n",
    "- Call:\n",
    "    - Multi-modal with peaks at 35, 42, 52, 66, and 89.\n",
    "    - Center at (decribed by median) 49.935.\n",
    "    - Maximum at 89.5\n",
    "    - Minimum at 32.54.\n",
    "\n",
    "- Email + Call\n",
    "    - Lowest number of transactions\n",
    "    - Multi-modal with peaks at 87.5, 127.5, 152.5, 185, and 227.5\n",
    "    - Center at (described by median) 182.135, highest center of all three methods.\n",
    "    - Maximum at 238.32, highest maximum of all three methods.\n",
    "    - Minumum at 89.5, highest minum of all three methods.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_method = df[df['sales_method'] == 'Email']\n",
    "call_method = df[df['sales_method'] == 'Call']\n",
    "call_email_method = df[df['sales_method'] == 'Email + Call']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['revenue'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_plot(df[['revenue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_plot(email_method[['revenue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_plot(call_method[['revenue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_plot(call_email_method[['revenue']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Was there any difference in revenue over time for each of the methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Call and Call+Email saw better results as the weeks went on, both with peaking revenue at week 5.\n",
    "    - Second largest value at week six for Email + Call.\n",
    "\n",
    "2. The Email method started very strong compared to the other two methods, peaking at week 1. Given the number of transactions this method saw the highest revenue for each week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revnue_group = df.groupby(by=['week', 'sales_method'])['revenue'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(revnue_group, x='week', y='revenue', color='sales_method', barmode='group', text=revnue_group['revenue'].apply(lambda x: round(x, 2)), labels={'revenue': 'Revenue'}) \n",
    "\n",
    "fig.update_traces(textposition='inside') \n",
    "\n",
    "fig.update_layout(title='Revenue by Week and Sales Method',\n",
    "                  xaxis_title='Week',\n",
    "                  yaxis_title='Revenue')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric to Monitor\n",
    "Since the business problem is trying to tackle efficiency, I suggest using the following definition:\n",
    "\n",
    "Revenue / Number of Site Visits\n",
    "\n",
    "This metric will measure the amount of revenue brought into the company per site visit. Without knowing the cost of a site visit, this may be not practical. I am assuming this is the highest cost for the sales team during their sales cycle (vs calling, emailing, etc.).\n",
    "\n",
    "This feature also had the highest correlaiton with our goal, revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['revenue_per_visit'] = df['revenue'] / df['nb_site_visits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_site_visit_group = df.groupby(by=['week', 'sales_method'])['revenue_per_visit'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(revenue_site_visit_group, x='week', y='revenue_per_visit', color='sales_method', barmode='group', text=revenue_site_visit_group['revenue_per_visit'].apply(lambda x: round(x, 2)), labels={'revenue_per_visit': 'Revenue Per Visit'}) \n",
    "\n",
    "fig.update_traces(textposition='inside') \n",
    "\n",
    "fig.update_layout(title='Revenue Per Visit by Week and Sales Method',\n",
    "                  xaxis_title='Week',\n",
    "                  yaxis_title='Average Revenue Per Visit')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Results\n",
    "Judging by our initial values for this metric, we see that Email + Call yields the highest Revenue/Visit across all 6 weeks. Despite revenue needing to ramp up, the investment of both sales strategies (Email + Call) may yield greater returns when visiting potential/current customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "I suggest the business to move forward with the Email + Call sales strategy as it yields the highest Revenue/Visit ratio. If visits are not a high cost part of the sales cycle, I suggest moving forward with just the Email strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
